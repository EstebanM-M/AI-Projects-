{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Building Advanced Transformers**\n",
    "\n",
    "**Estimated time needed:  30 minutes**  \n",
    "\n",
    "In this lab, you will implement and experiment with advanced Transformer models using Keras. \n",
    "\n",
    "**Learning objectives:** \n",
    "\n",
    "By the end of this lab, you will: \n",
    "\n",
    "- Implement advanced Transformer models using Keras. \n",
    "\n",
    "- Apply Transformers to real-world sequential data tasks. \n",
    "\n",
    "- Build, train, and evaluate Transformer models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Instructions: \n",
    "\n",
    "### Step 1: Import necessary libraries \n",
    "\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-19.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.15.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (645.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.0/645.0 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-19.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (404 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, pyarrow, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.2.2 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 keras-3.9.2 libclang-18.1.1 markdown-3.8 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.0.8 numpy-2.1.3 opt-einsum-3.4.0 optree-0.15.0 protobuf-5.29.4 pyarrow-19.0.1 rich-14.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.0.1 werkzeug-3.1.3 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m168.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (2.1.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.57.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.10.1 pillow-11.2.1 pyparsing-3.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pyarrow \n",
    "%pip install pandas  \n",
    "%pip install scikit-learn \n",
    "%pip install matplotlib \n",
    "%pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 19:03:37.021231: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-16 19:03:37.022949: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-16 19:03:37.029219: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-16 19:03:37.048478: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744830217.072819     301 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744830217.079087     301 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744830217.097402     301 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744830217.097433     301 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744830217.097435     301 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744830217.097437     301 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-16 19:03:37.103412: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setup the Environment to generate synthetic stock price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a synthetic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_prices.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_prices.csv', index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv('stock_prices.csv') \n",
    "data = data[['Close']].values \n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "`tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "`stock_prices.csv` is the data set that is loaded. \n",
    "\n",
    "`MinMaxScaler` method is used to normalize the data.  \n",
    "\n",
    "`create_dataset`method is used to prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Multi-Head Self-Attention \n",
    "\n",
    "Define the Multi-Head Self-Attention mechanism. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously. \n",
    "\n",
    "- The attention parameter computes the attention scores and weighted sum of the values. \n",
    "\n",
    "- The split_heads parameter splits the input into multiple heads for parallel attention computation. \n",
    "\n",
    "- The call method applies the self-attention mechanism and combines the heads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Transformer block \n",
    "\n",
    "Define the Transformer block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "\n",
    "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
    "\n",
    "- Dropout is used to prevent overfitting. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Encoder Layer \n",
    "\n",
    "Define the Encoder layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(EncoderLayer, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture. \n",
    "\n",
    "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network. \n",
    "\n",
    "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement Transformer encoder \n",
    "\n",
    "Define the Transformer Encoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 19:04:00.414084: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout \n",
    "\n",
    "class MultiHeadSelfAttention(Layer): \n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    " \n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "class TransformerBlock(Layer): \n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n",
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "\n",
    "# Example usage \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "print(outputs.shape)  # Should print (1, 100, 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build and Compile the Transformer model \n",
    "\n",
    "Integrate the Transformer Encoder into a complete model for sequential data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
    "\n",
    "- The model is then compiled with the Adam optimizer and mean squared error loss. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Transformer model \n",
    "\n",
    "Train the model on the prepared dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - loss: 12.7483   \n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - loss: 0.2290 \n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.1643\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1497\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.1782   \n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.1924 \n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1390\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.1229\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1666 \n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1134 \n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.1399\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1154 \n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - loss: 0.0800 \n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0996 \n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - loss: 0.1460 \n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0601 \n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1369\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0532 \n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0498 \n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0364 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fb1eeb4c890>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate and Make Predictions \n",
    "\n",
    "Evaluate the model's performance and make predictions on the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 311ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions \n",
    "predictions = model.predict(X) \n",
    "predictions = scaler.inverse_transform(predictions) \n",
    " \n",
    "\n",
    "# Plot the predictions \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(data, label='True Data') \n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.show() \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler. \n",
    "\n",
    "- The true data and predictions are plotted to visualize the model's performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises: \n",
    "\n",
    " ### Exercise 1: Add dropout to the Transformer model \n",
    "\n",
    " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Add a dropout layer after the Flatten layer in the model. \n",
    "\n",
    "- Set the dropout rate to 0.5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - loss: 8.4455  \n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 1.3083 \n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.7441 \n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.3312 \n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.1764 \n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.1587 \n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.1216 \n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0597 \n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0502 \n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0452 \n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0317   \n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0339 \n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0290   \n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0443 \n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 0.0297 \n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0283 \n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 963ms/step - loss: 0.0214\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 919ms/step - loss: 0.0214\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 890ms/step - loss: 0.0221\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 894ms/step - loss: 0.0182\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 257ms/step - loss: 0.0040\n",
      "Test loss: 0.0068048532120883465\n"
     ]
    }
   ],
   "source": [
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Experiment with different batch sizes \n",
    "\n",
    "**Objective: Observe the impact of different batch sizes on model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Train the model with a batch size of 16. \n",
    "\n",
    "- Train the model with a batch size of 64. \n",
    "\n",
    "- Compare the training time and performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 533ms/step - loss: 0.0241 \n",
      "Epoch 2/20\n",
      "\u001b[1m 87/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 532ms/step - loss: 0.0319"
     ]
    }
   ],
   "source": [
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a different activation function \n",
    "\n",
    " **Objective: Understand how different activation functions impact the model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Change the activation function of the Dense layer to `tanh`. \n",
    "\n",
    "- Train and evaluate the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "28ac4fd81c1d713f83dcd1cdf1d3383ad25ea92873288fe9e978e9a17b314709"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
