{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Implementing Transformers for Text Generation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will learn to implement Transformers for text generation tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "- Implement Transformers for text generation tasks \n",
    "\n",
    "- Build, train, and evaluate Transformer models for text generation using TensorFlow and Keras \n",
    "\n",
    "- Apply text generation in real-world scenarios \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-step instructions \n",
    "\n",
    "#### Step 1: Set up the environment \n",
    "\n",
    "- Import necessary libraries and load the data set \n",
    "\n",
    "- Preprocess the dataset for training \n",
    "\n",
    "In the following code: \n",
    "\n",
    "- Import TensorFlow and other necessary libraries. \n",
    "\n",
    "- Load the Shakespeare text dataset. \n",
    "\n",
    "- Preprocess the data set using the TextVectorization layer to convert text into integer sequences. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.16.2\n",
      "  Downloading tensorflow-2.16.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow==2.16.2)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow==2.16.2)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow==2.16.2)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.16.2)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow==2.16.2)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow==2.16.2)\n",
      "  Downloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow==2.16.2)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.2)\n",
      "  Downloading ml_dtypes-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow==2.16.2)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.2) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.16.2)\n",
      "  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.2) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.2) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.2) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.16.2)\n",
      "  Downloading termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.2) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow==2.16.2)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.16.2)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.2)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow==2.16.2)\n",
      "  Downloading keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from tensorflow==2.16.2)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.16.2) (0.45.1)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow==2.16.2)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow==2.16.2)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow==2.16.2)\n",
      "  Downloading optree-0.15.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow==2.16.2)\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow==2.16.2)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow==2.16.2)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow==2.16.2)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.16.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (590.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.8/590.8 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (404 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.2.2 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 keras-3.9.2 libclang-18.1.1 markdown-3.8 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.8 numpy-1.26.4 opt-einsum-3.4.0 optree-0.15.0 protobuf-4.25.6 rich-14.0.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.2 termcolor-3.0.1 werkzeug-3.1.3 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.16.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 21:18:29.416050: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-21 21:18:29.417389: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-21 21:18:29.424078: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-21 21:18:29.437149: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-21 21:18:29.459725: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-21 21:18:29.459766: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-21 21:18:29.475425: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-21 21:18:32.515123: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow.keras.layers import TextVectorization \n",
    "from tensorflow.keras.utils import get_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "path_to_file = get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt') \n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8') \n",
    "\n",
    "# Preview the dataset \n",
    "print(text[:1000]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized text shape: (202646,)\n",
      "First 10 vectorized tokens: [ 89 270 138  36 982 144 673 125  16 106]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 21:18:33.763239: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the dataset \n",
    "vocab_size = 10000 \n",
    "seq_length = 100 \n",
    "\n",
    "# Adapt TextVectorization to full text \n",
    "vectorizer = TextVectorization(max_tokens=vocab_size, output_mode='int') \n",
    "text_ds = tf.data.Dataset.from_tensor_slices([text]).batch(1) \n",
    "vectorizer.adapt(text_ds) \n",
    "\n",
    "# Vectorize the text \n",
    "vectorized_text = vectorizer([text])[0] \n",
    "print(\"Vectorized text shape:\", vectorized_text.shape) \n",
    "print(\"First 10 vectorized tokens:\", vectorized_text.numpy()[:10]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Create input and target sequences \n",
    "\n",
    "Generate input and target sequences for training the Transformer model. \n",
    "\n",
    "In the following code: \n",
    "\n",
    "- Define a function to generate input and target sequences. \n",
    "\n",
    "- Split the text data into sequences of the specified length. \n",
    "\n",
    "- Convert the sequences into TensorFlow tensors for training. \n",
    "\n",
    "Generative sequence: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences generated: 202546\n",
      "Sample input sequence: [  89  270  138   36  982  144  673  125   16  106   34  106  106   89\n",
      "  270    7   41   34 1286  344    4  200   64    4 3690   34 1286 1286\n",
      "   89  270   89    7   93 1187  225   12 2442  592    4    2  307   34\n",
      "   36 2655   36 2655   89  270   72   79  506   27    3   56   24 1390\n",
      "   57   40  161 2328  644    9 4980   34   32   54 2863  885   72   17\n",
      "   18  163  146  146  165  270   74  218   46  595   89  270   36   41\n",
      " 6739  172  595    2 1780   46   29 1323 5151   47   58 4151   79   39\n",
      "   60   58]\n",
      "Shape of X: (202546, 100)\n",
      "Shape of Y: (202546, 100)\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(text, seq_length): \n",
    "    input_seqs = [] \n",
    "    target_seqs = [] \n",
    "    for i in range(len(text) - seq_length): \n",
    "        input_seq = text[i:i + seq_length] \n",
    "        target_seq = text[i + 1:i + seq_length + 1] \n",
    "        input_seqs.append(input_seq) \n",
    "        target_seqs.append(target_seq) \n",
    "    return np.array(input_seqs), np.array(target_seqs) \n",
    "\n",
    "# Generate sequences \n",
    "X, Y = create_sequences(vectorized_text.numpy(), seq_length) \n",
    "\n",
    "# Check if sequences are correctly generated \n",
    "print(\"Number of sequences generated:\", len(X)) \n",
    "print(\"Sample input sequence:\", X[0] if len(X) > 0 else \"No sequences generated\") \n",
    "\n",
    "# Check if X and Y are not empty \n",
    "assert X.size > 0, \"Input data X is empty\" \n",
    "assert Y.size > 0, \"Target data Y is empty\" \n",
    "X = tf.convert_to_tensor(X) \n",
    "Y = tf.convert_to_tensor(Y) \n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Build the Transformer model \n",
    "\n",
    "Define the Transformer model architecture for text generation. \n",
    "\n",
    "In the following code: \n",
    "\n",
    "- Define the TransformerBlock class that includes multi-head attention and feedforward layers with normalization and dropout. \n",
    "\n",
    "- Define the TransformerModel class, including embedding, positional encoding, and multiple Transformer blocks. \n",
    "\n",
    "- Compile the Transformer model using the Adam optimizer and sparse categorical cross-entropy loss function. \n",
    "\n",
    "Transformer model: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, MultiHeadAttention, Dense, LayerNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class TransformerModel(Model):  # Model is now properly imported\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, ff_dim, num_layers, seq_length):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = Embedding(vocab_size, embed_dim)\n",
    "        self.pos_encoding = self.positional_encoding(seq_length, embed_dim)\n",
    "        self.transformer_blocks = [TransformerBlock(embed_dim, num_heads, ff_dim) for _ in range(num_layers)]\n",
    "        self.dense = Dense(vocab_size)\n",
    "\n",
    "    def positional_encoding(self, seq_length, embed_dim):\n",
    "        angle_rads = self.get_angles(np.arange(seq_length)[:, np.newaxis], np.arange(embed_dim)[np.newaxis, :], embed_dim)\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        pos_encoding = angle_rads[np.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "    def get_angles(self, pos, i, embed_dim):\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(embed_dim))\n",
    "        return pos * angle_rates\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        x = self.embedding(inputs)\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        for transformer_block in self.transformer_blocks:\n",
    "            x = transformer_block(x, training=training)  # Pass training argument correctly\n",
    "        output = self.dense(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,840</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_1             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,840</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_2             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,840</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_3             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,840</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │     \u001b[38;5;34m2,560,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block               │ ?                      │     \u001b[38;5;34m1,315,840\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_1             │ ?                      │     \u001b[38;5;34m1,315,840\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_2             │ ?                      │     \u001b[38;5;34m1,315,840\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_3             │ ?                      │     \u001b[38;5;34m1,315,840\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m10000\u001b[0m)        │     \u001b[38;5;34m2,570,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,393,360</span> (39.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,393,360\u001b[0m (39.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,393,360</span> (39.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,393,360\u001b[0m (39.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparameters \n",
    "embed_dim = 256 \n",
    "num_heads = 4 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Build the Transformer model \n",
    "model = TransformerModel(vocab_size, embed_dim, num_heads, ff_dim, num_layers, seq_length)\n",
    "\n",
    "# Provide input shape to build the model by passing a dummy input with maxval specified\n",
    "_ = model(tf.random.uniform((1, seq_length), maxval=vocab_size, dtype=tf.int32))\n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Summary of the model \n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Train the Transformer model \n",
    "\n",
    "Train the Transformer model on the preprocessed text data. \n",
    "\n",
    "In the following code: \n",
    "\n",
    "- Train the Transformer model on the input and target sequences \n",
    "\n",
    "- Plot the training loss to monitor the model's performance over epochs \n",
    "\n",
    "Model training: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.57.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.10.1 pillow-11.2.1 pyparsing-3.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m3324/6330\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5:17:16\u001b[0m 6s/step - loss: 11.7158 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Train the transformer model on the full input and target sequences\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Plot training loss to monitor model performance over epochs\u001b[39;00m\n\u001b[1;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for training visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Early stopping callback to stop training if the loss doesn't improve\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# Train the transformer model on the full input and target sequences\n",
    "history = model.fit(X, Y, epochs=20, batch_size=32, callbacks=[early_stopping])\n",
    "\n",
    "# Plot training loss to monitor model performance over epochs\n",
    "plt.plot(history.history['loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Generate text with the trained model \n",
    "\n",
    "Define a function to generate text using the trained Transformer model. \n",
    "\n",
    "In the following code: \n",
    "\n",
    "- Define the generate_text function to generate text using the trained Transformer model \n",
    "\n",
    "- Convert the start string into numerical format \n",
    "\n",
    "- Use the model to predict the next word and append it to the generated text \n",
    "\n",
    "- Print the generated text \n",
    "\n",
    "#### Text generation: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, num_generate=100, temperature=1.0):\n",
    "    # Convert the start string to a vectorized format\n",
    "    input_eval = vectorizer([start_string]).numpy()\n",
    "    \n",
    "    # Ensure the input length is the same as the model's expected input shape\n",
    "    if input_eval.shape[1] < seq_length:\n",
    "        # Pad the input if it's shorter than the expected sequence length\n",
    "        padding = np.zeros((1, seq_length - input_eval.shape[1]))\n",
    "        input_eval = np.concatenate((padding, input_eval), axis=1)\n",
    "    elif input_eval.shape[1] > seq_length:\n",
    "        # Truncate the input if it's longer than the expected sequence length\n",
    "        input_eval = input_eval[:, -seq_length:]\n",
    "\n",
    "    input_eval = tf.convert_to_tensor(input_eval)\n",
    "    \n",
    "    # Initialize an empty list to store generated text\n",
    "    text_generated = []\n",
    "\n",
    "    # Start generating text\n",
    "    for i in range(num_generate):\n",
    "        # Make predictions using the model\n",
    "        predictions = model(input_eval)\n",
    "\n",
    "        # Remove only the batch dimension, keep the logits as 2D (batch_size, vocab_size)\n",
    "        predictions = predictions[0]  # This should be of shape [vocab_size]\n",
    "\n",
    "        # Apply temperature to predictions\n",
    "        predictions = predictions / temperature\n",
    "        \n",
    "        # Use a categorical distribution to predict the next word\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[0, 0].numpy()\n",
    "\n",
    "        # Update the input tensor to include the predicted word, maintaining the sequence length\n",
    "        input_eval = np.append(input_eval.numpy(), [[predicted_id]], axis=1)  # Append predicted token\n",
    "        input_eval = input_eval[:, -seq_length:]  # Keep only the last `seq_length` tokens\n",
    "        input_eval = tf.convert_to_tensor(input_eval)  # Convert back to tensor\n",
    "\n",
    "        # Append the predicted word to the generated text\n",
    "        text_generated.append(vectorizer.get_vocabulary()[predicted_id])\n",
    "\n",
    "    # Return the generated text starting from the initial seed\n",
    "    return start_string + ' ' + ' '.join(text_generated)\n",
    "\n",
    "# Generate text with temperature control\n",
    "start_string = \"To be, or not to be\"\n",
    "generated_text = generate_text(model, start_string, temperature=0.7)  # Lower temperature for more focused predictions\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice exercises \n",
    "\n",
    "### Exercise 1: Experiment with different sequence lengths \n",
    "\n",
    "**Objective:** Implement different sequence lengths to understand their effect on the performance of the Transformer model. \n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Change the sequence length to 50 \n",
    "\n",
    "- Preprocess the data set with the new sequence length \n",
    "\n",
    "- Train the model and compare the training loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 tzdata-2025.2\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m144.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n",
      "Number of samples in the dataset: 30\n",
      "Dataset is very small. Using 50% of the data for training.\n",
      "Shape of X: (24, 5, 1)\n",
      "Shape of Y: (24,)\n",
      "Epoch 1/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 2.2834\n",
      "Epoch 2/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6296 \n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7846 \n",
      "Epoch 4/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4659 \n",
      "Epoch 5/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1001 \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example: Load a time-series dataset\n",
    "data_url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/WHA_mc9FWSVjCGLSLAp48A/stock-prices.csv'\n",
    "df = pd.read_csv(data_url)\n",
    "\n",
    "# Select the 'Close' column for training (or any relevant column for your task)\n",
    "data = df[['Close']].values\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Check the number of samples in the data\n",
    "n_samples = data.shape[0]\n",
    "print(f\"Number of samples in the dataset: {n_samples}\")\n",
    "\n",
    "# Ensure we have enough data by setting a reasonable train size\n",
    "if n_samples < 100:\n",
    "    print(\"Dataset is very small. Using 50% of the data for training.\")\n",
    "    train_size = 0.5  # Use 50% of data if we have less than 100 samples\n",
    "    seq_length = 5    # Use a shorter sequence length for very small datasets\n",
    "else:\n",
    "    train_size = 0.1  # Use 10% of data for larger datasets\n",
    "    seq_length = 50   # Change sequence length to 50 for larger datasets\n",
    "\n",
    "# Reduce dataset size for quicker runs\n",
    "X, _, Y, _ = train_test_split(data, data, train_size=train_size, random_state=42)  # Adjust train_size based on data\n",
    "\n",
    "# Preprocess the dataset with adjusted sequence length\n",
    "def create_dataset(data, time_step=seq_length):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "X, Y = create_dataset(data, seq_length)\n",
    "\n",
    "# Check if the generated sequences have valid shapes\n",
    "if X.size == 0 or Y.size == 0:\n",
    "    raise ValueError(f\"The dataset is too small to create sequences with a length of {seq_length}. Reduce the sequence length or use a larger dataset.\")\n",
    "\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of Y:\", Y.shape)\n",
    "\n",
    "# Define a simpler Transformer Block for faster runs\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):  # Set training argument default to False\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "# Build and compile the model\n",
    "input_shape = (X.shape[1], X.shape[2])\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "x = tf.keras.layers.Dense(64)(inputs)  # Reduced embed_dim for faster runs\n",
    "transformer_block = TransformerBlock(embed_dim=64, num_heads=4, ff_dim=128)  # Reduced model complexity\n",
    "x = transformer_block(x, training=True)  # Pass training argument here\n",
    "flatten = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(1)(flatten)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Early stopping to stop training when no improvement is seen\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# Train the model with reduced epochs and steps\n",
    "history = model.fit(X, Y, epochs=5, batch_size=32, steps_per_epoch=10, callbacks=[early_stopping])  # Reduced epochs and steps per epoch\n",
    "\n",
    "# Plot training loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example: Load a time-series dataset\n",
    "data_url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/WHA_mc9FWSVjCGLSLAp48A/stock-prices.csv'\n",
    "df = pd.read_csv(data_url)\n",
    "\n",
    "# Select the 'Close' column for training (or any relevant column for your task)\n",
    "data = df[['Close']].values\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Check the number of samples in the data\n",
    "n_samples = data.shape[0]\n",
    "print(f\"Number of samples in the dataset: {n_samples}\")\n",
    "\n",
    "# Ensure we have enough data by setting a reasonable train size\n",
    "if n_samples < 100:\n",
    "    print(\"Dataset is very small. Using 50% of the data for training.\")\n",
    "    train_size = 0.5  # Use 50% of data if we have less than 100 samples\n",
    "    seq_length = 5    # Use a shorter sequence length for very small datasets\n",
    "else:\n",
    "    train_size = 0.1  # Use 10% of data for larger datasets\n",
    "    seq_length = 50   # Change sequence length to 50 for larger datasets\n",
    "\n",
    "# Reduce dataset size for quicker runs\n",
    "X, _, Y, _ = train_test_split(data, data, train_size=train_size, random_state=42)  # Adjust train_size based on data\n",
    "\n",
    "# Preprocess the dataset with adjusted sequence length\n",
    "def create_dataset(data, time_step=seq_length):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "X, Y = create_dataset(data, seq_length)\n",
    "\n",
    "# Check if the generated sequences have valid shapes\n",
    "if X.size == 0 or Y.size == 0:\n",
    "    raise ValueError(f\"The dataset is too small to create sequences with a length of {seq_length}. Reduce the sequence length or use a larger dataset.\")\n",
    "\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of Y:\", Y.shape)\n",
    "\n",
    "# Define a simpler Transformer Block for faster runs\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):  # Set training argument default to False\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "# Build and compile the model\n",
    "input_shape = (X.shape[1], X.shape[2])\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "x = tf.keras.layers.Dense(64)(inputs)  # Reduced embed_dim for faster runs\n",
    "transformer_block = TransformerBlock(embed_dim=64, num_heads=4, ff_dim=128)  # Reduced model complexity\n",
    "x = transformer_block(x, training=True)  # Pass training argument here\n",
    "flatten = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(1)(flatten)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Early stopping to stop training when no improvement is seen\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# Train the model with reduced epochs and steps\n",
    "history = model.fit(X, Y, epochs=5, batch_size=32, steps_per_epoch=10, callbacks=[early_stopping])  # Reduced epochs and steps per epoch\n",
    "\n",
    "# Plot training loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Add a learning rate scheduler \n",
    "\n",
    "**Objective:** Implement a learning rate scheduler to adjust the learning rate during training. \n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Define a learning rate scheduler that reduces the learning rate by half every 10 epochs \n",
    "\n",
    "- Train the model with the learning rate scheduler and compare the training loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.5327 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4346 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.5109 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.2589 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.2126 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0771 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.2210 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3020 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3237 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3139 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.2784 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0826 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1476 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1808 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1295 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1217 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1229 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1481 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1449 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.1557 - learning_rate: 5.0000e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a learning rate scheduler  \n",
    "def scheduler(epoch, lr):  \n",
    "    if epoch % 10 == 0 and epoch != 0:  \n",
    "        lr = lr * 0.5  \n",
    "    return lr  \n",
    " \n",
    "\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)  \n",
    "\n",
    "\n",
    "# Train the model with the learning rate scheduler  \n",
    "history = model.fit(X, Y, epochs=20, batch_size=64, callbacks=[callback])  \n",
    "   \n",
    "\n",
    "# Plot the training loss  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.title('Training Loss with Learning Rate Scheduler')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a learning rate scheduler  \n",
    "def scheduler(epoch, lr):  \n",
    "    if epoch % 10 == 0 and epoch != 0:  \n",
    "        lr = lr * 0.5  \n",
    "    return lr  \n",
    " \n",
    "\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)  \n",
    "\n",
    "\n",
    "# Train the model with the learning rate scheduler  \n",
    "history = model.fit(X, Y, epochs=20, batch_size=64, callbacks=[callback])  \n",
    "   \n",
    "\n",
    "# Plot the training loss  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.title('Training Loss with Learning Rate Scheduler')  \n",
    "plt.show() \n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Generate longer text sequences \n",
    "\n",
    "**Objective:** To explore the model's text generation capabilities and generate longer sequences. \n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Modify the `generate_text` function to generate 200 tokens instead of 100 \n",
    "\n",
    "- Generate text using the trained model and the modified function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_text(model, start_string, num_generate=200):\n",
    "    # Convert the start string to numbers (vectorize)\n",
    "    input_eval = vectorizer([start_string]).numpy()\n",
    "\n",
    "    # Ensure the input tensor has the correct shape\n",
    "    input_eval = tf.convert_to_tensor(input_eval[:, -5:])  # Ensure it has a shape of (1, 5)\n",
    "    \n",
    "    text_generated = []\n",
    "\n",
    "    for i in range(num_generate):\n",
    "        # Make predictions using the model\n",
    "        predictions = model(input_eval)\n",
    "\n",
    "        # Ensure predictions is a matrix with shape [batch_size, num_classes]\n",
    "        predictions = tf.squeeze(predictions, 0)  # Remove the batch dimension\n",
    "        predictions = tf.expand_dims(predictions, 0)  # Add back a batch dimension for categorical\n",
    "        \n",
    "        # Use a categorical distribution to predict the next word\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Update the input tensor to include the predicted word, maintaining the sequence length\n",
    "        input_eval = np.append(input_eval.numpy(), [[predicted_id]], axis=1)  # Append predicted token\n",
    "        input_eval = input_eval[:, -5:]  # Keep only the last 5 tokens to match input shape\n",
    "        input_eval = tf.convert_to_tensor(input_eval)  # Convert back to tensor\n",
    "        \n",
    "        # Add the predicted word to the generated text\n",
    "        text_generated.append(vectorizer.get_vocabulary()[predicted_id])\n",
    "\n",
    "    return start_string + ' ' + ' '.join(text_generated)\n",
    "\n",
    "\n",
    "# Generate longer text\n",
    "start_string = \"To be, or not to be\"\n",
    "generated_text = generate_text(model, start_string)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_text(model, start_string, num_generate=200):\n",
    "    # Convert the start string to numbers (vectorize)\n",
    "    input_eval = vectorizer([start_string]).numpy()\n",
    "\n",
    "    # Ensure the input tensor has the correct shape\n",
    "    input_eval = tf.convert_to_tensor(input_eval[:, -5:])  # Ensure it has a shape of (1, 5)\n",
    "    \n",
    "    text_generated = []\n",
    "\n",
    "    for i in range(num_generate):\n",
    "        # Make predictions using the model\n",
    "        predictions = model(input_eval)\n",
    "\n",
    "        # Ensure predictions is a matrix with shape [batch_size, num_classes]\n",
    "        predictions = tf.squeeze(predictions, 0)  # Remove the batch dimension\n",
    "        predictions = tf.expand_dims(predictions, 0)  # Add back a batch dimension for categorical\n",
    "        \n",
    "        # Use a categorical distribution to predict the next word\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Update the input tensor to include the predicted word, maintaining the sequence length\n",
    "        input_eval = np.append(input_eval.numpy(), [[predicted_id]], axis=1)  # Append predicted token\n",
    "        input_eval = input_eval[:, -5:]  # Keep only the last 5 tokens to match input shape\n",
    "        input_eval = tf.convert_to_tensor(input_eval)  # Convert back to tensor\n",
    "        \n",
    "        # Add the predicted word to the generated text\n",
    "        text_generated.append(vectorizer.get_vocabulary()[predicted_id])\n",
    "\n",
    "    return start_string + ' ' + ' '.join(text_generated)\n",
    "\n",
    "\n",
    "# Generate longer text\n",
    "start_string = \"To be, or not to be\"\n",
    "generated_text = generate_text(model, start_string)\n",
    "\n",
    "print(generated_text)\n",
    " \n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion \n",
    "\n",
    "Congratulations on completing this lab! You have successfully built and trained a Transformer model for text generation in this lab using TensorFlow and Keras. You learned how to preprocess text data, create input and target sequences, define the Transformer model architecture, train the model, and generate text using the trained model. By completing this lab, you gained hands-on experience with Transformers for text generation and explored practical applications of this robust model architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "2e6ca7cd09b5cd4f1194960912f1c49074e07ec8eedd449d96e6d372faa57813"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
